{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83e\uddd1\u200d\ud83d\udcbb Fraud Detection Exploration Notebook\n", "\n", "This notebook demonstrates an end-to-end mini workflow:\n", "- Generate synthetic fraud dataset (1000 rows)\n", "- Perform EDA\n", "- Train XGBoost model with SageMaker\n", "- Evaluate model\n", "- Deploy to real-time endpoint\n", "- Invoke endpoint with sample transaction"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import boto3\n", "import pandas as pd\n", "import numpy as np\n", "import sagemaker\n", "from sagemaker import get_execution_role\n", "from sagemaker.xgboost.estimator import XGBoost\n", "import matplotlib.pyplot as plt\n", "\n", "session = sagemaker.Session()\n", "role = get_execution_role()\n", "bucket = session.default_bucket()\n", "prefix = \"fraud-detection\"\n", "\n", "print(f\"Using S3 bucket: {bucket}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Generate Synthetic Fraud Dataset (1000 rows)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(42)\n", "n = 1000\n", "\n", "data = {\n", "    \"txn_id\": np.arange(1, n+1),\n", "    \"amount\": np.random.exponential(scale=100, size=n).round(2),\n", "    \"time_delta\": np.random.exponential(scale=60, size=n).round(2),\n", "    \"device_score\": np.random.uniform(0, 1, n).round(3),\n", "    \"geo_distance\": np.random.exponential(scale=50, size=n).round(2),\n", "    \"num_prev_txns\": np.random.poisson(lam=3, size=n),\n", "    \"is_night\": np.random.choice([0, 1], size=n, p=[0.7, 0.3])\n", "}\n", "\n", "df = pd.DataFrame(data)\n", "\n", "fraud_prob = (\n", "    0.2*(df[\"amount\"] > 500).astype(int) +\n", "    0.2*(df[\"geo_distance\"] > 100).astype(int) +\n", "    0.2*(df[\"is_night\"] == 1).astype(int) +\n", "    0.1*(df[\"device_score\"] < 0.3).astype(int)\n", ")\n", "fraud_prob = np.clip(fraud_prob, 0, 1)\n", "df[\"fraud_label\"] = (np.random.rand(n) < fraud_prob).astype(int)\n", "\n", "print(df.head())\n", "df.to_csv(\"synthetic_fraud_data.csv\", index=False)\n", "print(\"\u2705 synthetic_fraud_data.csv generated with\", n, \"rows\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Basic EDA"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(df['fraud_label'].value_counts())\n", "df['amount'].hist(bins=50)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train/Test Split & Upload to S3"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "\n", "X = df.drop(['fraud_label','txn_id'], axis=1)\n", "y = df['fraud_label']\n", "\n", "scaler = StandardScaler()\n", "X_scaled = scaler.fit_transform(X)\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n", "\n", "train = pd.concat([pd.Series(y_train.values), pd.DataFrame(X_train)], axis=1)\n", "test = pd.concat([pd.Series(y_test.values), pd.DataFrame(X_test)], axis=1)\n", "\n", "train_file = 'train.csv'\n", "test_file = 'test.csv'\n", "train.to_csv(train_file, header=False, index=False)\n", "test.to_csv(test_file, header=False, index=False)\n", "\n", "train_s3 = session.upload_data(train_file, bucket=bucket, key_prefix=prefix)\n", "test_s3 = session.upload_data(test_file, bucket=bucket, key_prefix=prefix)\n", "print(train_s3, test_s3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train XGBoost Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, version=\"1.5-1\")\n", "xgb = XGBoost(entry_point=None,\n", "              framework_version=\"1.5-1\",\n", "              instance_type=\"ml.m5.large\",\n", "              instance_count=1,\n", "              role=role,\n", "              output_path=f\"s3://{bucket}/{prefix}/output\",\n", "              use_spot_instances=True,\n", "              max_run=3600,\n", "              max_wait=7200,\n", "              hyperparameters={\n", "                  \"max_depth\": 5,\n", "                  \"eta\": 0.2,\n", "                  \"gamma\": 4,\n", "                  \"min_child_weight\": 6,\n", "                  \"subsample\": 0.8,\n", "                  \"objective\": \"binary:logistic\",\n", "                  \"num_round\": 200\n", "              })\n", "\n", "xgb.fit({\"train\": train_s3, \"validation\": test_s3})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Deploy Endpoint"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["predictor = xgb.deploy(initial_instance_count=1, instance_type=\"ml.m5.large\")\n", "print(\"Endpoint deployed:\", predictor.endpoint_name)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Test Endpoint"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sample = X_test[0:1]\n", "result = predictor.predict(sample)\n", "print(\"Fraud score:\", result)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (Data Science)", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 5}